{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f6579-19e3-41bd-8460-5ef9f5068658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "if os.path.exists('Y:/VIDEOS/1119/Videos/'):\n",
    "    print('Y:/VIDEOS/1119/Videos/ exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of Folders/Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "folder = 'Y:/VIDEOS'\n",
    "\n",
    "ids = os.listdir(folder)\n",
    "excluded_list = []\n",
    "for idx in ids:\n",
    "    \n",
    "    # check folder name\n",
    "    if os.path.exists(folder + '/' + idx + '/Videos/'):\n",
    "        print(f'idx: {idx}, folder: {folder + \"/\" + idx + \"/Videos/\"}')\n",
    "        files = glob.glob(folder + '/' + idx + '/Videos/*')\n",
    "    else:\n",
    "        # print(f'idx: {idx}, folder: {folder + \"/\" + idx + \"/Video/\"}')\n",
    "        files = glob.glob(folder + '/' + idx + '/**/*.asf')    \n",
    "\n",
    "    # check for 827 or 984\n",
    "    if os.path.exists(folder + '/' + idx + '/827000/') or os.path.exists(folder + '/' + idx + '/984/'):\n",
    "        print(f'idx: {idx}, 827 or 984')\n",
    "        excluded_list.append(idx)\n",
    "        continue\n",
    "    \n",
    "    # check for 827000 or 984 in nested folder\n",
    "    if os.path.exists(folder + '/' + idx + '/Video/827000/') or os.path.exists(folder + '/' + idx + '/Video/984/'):\n",
    "        print(f'idx: {idx}, 827 or 984')\n",
    "        excluded_list.append(idx)\n",
    "        continue \n",
    "\n",
    "    if len(files) < 1:\n",
    "        print(f'idx: {idx}, files: {len(files)}')\n",
    "        excluded_list.append(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e633cf",
   "metadata": {},
   "source": [
    "### Validation for Empty Video Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d653d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "folder = 'Y:/VIDEOS'\n",
    "# video_list = glob.glob(folder + '/*/Video/**/*.asf')\n",
    "# video_list\n",
    "\n",
    "ids = os.listdir(folder)\n",
    "excluded_list = []\n",
    "for idx in ids:\n",
    "    files = glob.glob(folder + '/' + idx + '/Video/**/*.asf')\n",
    "    if len(files) < 1:\n",
    "        print(f'idx: {idx}, files: {len(files)}')\n",
    "        excluded_list.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_list = ['1009 1010',\n",
    "                 '1011 1012',\n",
    "                 '1003 1004',\n",
    "                 '1031 1017',\n",
    "                 '1011 1012',\n",
    "                 '1043 1044',\n",
    "                 '1055 1056',\n",
    "                 '1074 1075',\n",
    "                 '1099 1100',\n",
    "                 '1013 1014',\n",
    "                 '1003 1004-nonAI',\n",
    "                 '1005-nonAI',\n",
    "                 '1073',\n",
    "                 '1082',\n",
    "                 '1094',\n",
    "                 '1097',\n",
    "                 '2002',\n",
    "                 '2062'\n",
    "                 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672caf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import metaData\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47c2d0-3e97-4738-9004-7192341864f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'Datafiles/data_storage_Jan2023.json'\n",
    "with open(json_file) as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b329e-eec5-4096-9999-dca66580f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_list = {}\n",
    "days = []\n",
    "for i, d in enumerate(data['data'][:500]):\n",
    "    if d['id'] in days_list.keys():\n",
    "        days_list[d['id']].append(d['day'])\n",
    "    elif d['id'] not in days_list.keys():\n",
    "        days_list[d['id']] = list()\n",
    "        days_list[d['id']].append(d['day'])\n",
    "    # print(f\"Index: {i}, Data: {d['day']}\")\n",
    "    # days.append(d['day'])\n",
    "\n",
    "days_list_sorted = {k: sorted(v) for k, v in days_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c16497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(json_file)\n",
    "dt = pd.DataFrame(df['data'], columns=['id', 'day', 'duration'])\n",
    "\n",
    "\n",
    "jn = pd.json_normalize(df['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fa3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = []\n",
    "ts_list = []\n",
    "for col, row in jn.iloc[:10].iterrows():\n",
    "    for idx in row:\n",
    "        # col_list.append(idx)\n",
    "        if type(idx) == list and len(idx) > 0:\n",
    "            for item in idx:\n",
    "                ts_list.append(item)\n",
    "        else:\n",
    "            col_list.append(idx)\n",
    "            if ts_list != []:\n",
    "                col_list.append(ts_list)\n",
    "                ts_list = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2302bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jn.columns\n",
    "\n",
    "ts_cols = ['yawn.timestamp',\n",
    "           'smoking.timestamp',\n",
    "           'mobilephone.timestamp',\n",
    "           'distraction.timestamp',\n",
    "           'eyeclosing.timestamp',\n",
    "           'crossinglane.timestamp',\n",
    "           'nearcollision.timestamp',\n",
    "           'stopsign.timestamp',\n",
    "           'redlight.timestamp',\n",
    "           'pedestrian.timestamp',\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f0e37",
   "metadata": {},
   "source": [
    "### Data Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef44c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sort a list of dictionaries by value1 and value2\n",
    "def sort_list_of_dict_by_value(list_of_dict, value1, value2):\n",
    "    return sorted(list_of_dict, key=lambda k: (k[value1], k[value2]))\n",
    "\n",
    "\n",
    "# get next 90 days from a given date\n",
    "# return a single date for next 90 days\n",
    "def get_next_90_days(start_date):\n",
    "    yyyy = start_date[:4]\n",
    "    mm = start_date[4:6]\n",
    "    dd = start_date[6:]\n",
    "\n",
    "    converted_date = datetime.datetime(int(yyyy), int(mm), int(dd))\n",
    "    next_months = converted_date + datetime.timedelta(days=90)\n",
    "    return str(next_months)[:10].replace('-', '')\n",
    "\n",
    "def get_next_90_days_data_from_sorted_list_of_dict(list_of_dict, value1, value2):\n",
    "    next_90_days = []\n",
    "    for i, d in enumerate(list_of_dict):\n",
    "        if i == len(list_of_dict)-1:\n",
    "            break\n",
    "        next_90_days.append(get_next_90_days(d[value2]))\n",
    "    return next_90_days\n",
    "\n",
    "# calculate number of day between two dates\n",
    "def days_between(d1, d2):\n",
    "    d1 = datetime.datetime.strptime(d1, \"%Y%m%d\")\n",
    "    d2 = datetime.datetime.strptime(d2, \"%Y%m%d\")\n",
    "    return abs((d2 - d1).days)\n",
    "\n",
    "# days_between('20200301', '20200102')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86273cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = sort_list_of_dict_by_value(data['data'], 'id', 'day')\n",
    "d = get_next_90_days_data_from_sorted_list_of_dict(sl, 'id', 'day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e29d4e",
   "metadata": {},
   "source": [
    "### Extracting Data Based on Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cb3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filePath = 'Z:/VIDEOS/1010/Disk_files/debug/'\n",
    "def extract_indices_from_log(filePath,file):\n",
    "    alarmsDict = {'NOBODY': 0, 'LOOKING_DOWN': 0, 'SMOKING': 0, 'CALLING':0, 'LDW': 0, 'EYE_CLOSED': 0, 'LDW_R': 0, 'LDW_L':0, 'FCW':0, 'camera cover!':0, 'infrared block!': 0 }\n",
    "    alarmsTimeStamp = {'NOBODY': [], 'LOOKING_DOWN': [], 'SMOKING': [], 'CALLING':[], 'LDW': [], 'EYE_CLOSED': [], 'LDW_R': [], 'LDW_L':[], 'FCW':[], 'camera cover!':[], 'infrared block!': [] }\n",
    "    # alarmsDict = {'alarm_type 5': 0, 'alarm_type 4': 0, 'alarm_type 3': 0, 'alarm_type 1': 0, 'alarm_type 2': 0, 'alarm_type 17': 0, 'alarm_type 18': 0, 'alarm_type 27':0, 'alarm_type 16':0, 'alarm_type 9':0, 'alarm_type 7': 0 }\n",
    "    # alarmsTimeStamp = {'alarm_type 5': [], 'alarm_type 4': [], 'alarm_type 3': [], 'alarm_type 1': [], 'alarm_type 2': [], 'alarm_type 17': [], 'alarm_type 18': [], 'alarm_type 27':[], 'alarm_type 16':[], 'alarm_type 9':[], 'alarm_type 7': [] }\n",
    "    \n",
    "    error_files = []\n",
    "    # print(f\"Processing debug file {file}\")\n",
    "    with open(os.path.join(filePath, file), 'r') as logFile:\n",
    "        lines = logFile.read().splitlines()\n",
    "        for line in lines:\n",
    "            words = line.split(\" \")\n",
    "            \"\"\"\n",
    "            Retrieve alarm will be here\n",
    "            \"\"\"\n",
    "            for alarm in alarmsDict.keys():\n",
    "                if alarm in words:\n",
    "                    alarmsDict[alarm] += 1\n",
    "                    # below is date extraction so needs to be corrected****** --> currently is this -->[20210504-140826][03][baseIVS]\n",
    "                    try:\n",
    "                        timestamp = \"\".join(words[0].split('[')[1].split('-')).strip(']')\n",
    "                        alarmsTimeStamp[alarm].append(timestamp)\n",
    "                    except Exception:\n",
    "                        error_files.append(file)\n",
    "\n",
    "        # logFile.close()\n",
    "        # print(alarmsDict)\n",
    "    return alarmsDict, alarmsTimeStamp, error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_list = ['1003 1004','1031 1017','1011 1012','1043 1044','1013 1014','1003 1004-nonAI', '1005-nonAI', '1073', '2062']\n",
    "ids = []\n",
    "for item in os.listdir('Z:/VIDEOS/'):\n",
    "    if item not in excluded_list:\n",
    "        ids.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile = []\n",
    "mapping = {'NOBODY': 0,\n",
    "           'LOOKING_DOWN': 1,\n",
    "           'SMOKING': 2, \n",
    "           'CALLING': 3, \n",
    "           'LDW': 5, \n",
    "           'EYE_CLOSED': 4, \n",
    "           'LDW_R': 5, \n",
    "           'LDW_L':5, \n",
    "           'FCW':6, \n",
    "           'camera cover!':0, \n",
    "           'infrared block!': 0 }\n",
    "    \n",
    "for each_driver in tqdm(ids):\n",
    "    logFolder = f'Z:/VIDEOS/{each_driver}/Disk_files/debug/'\n",
    "    for logfile in os.listdir(logFolder):\n",
    "        driverid = logFolder.split('/')[2]\n",
    "        \n",
    "        # if logfile.endswith('.log'):\n",
    "        alarmdict, alarmtimestamp, err = extract_indices_from_log(logFolder, logfile)\n",
    "        for key, value in alarmtimestamp.items():\n",
    "            for ts in value:\n",
    "                if key != 'NOBODY':\n",
    "                    id = driverid\n",
    "                    alarm_type = key\n",
    "                    date = ts[:9]\n",
    "                    \n",
    "                    transform_dict = {'id': id, 'date': date, 'timestamp': ts, 'type': mapping[alarm_type]}\n",
    "                    jsonfile.append(transform_dict)\n",
    "\n",
    "with open('./Datafiles/Timestamps_data.json', 'w') as jsonf:\n",
    "    json.dump(jsonfile, jsonf)    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Formatting the data to used in excel reprots\n",
    "import json\n",
    "\n",
    "with open('data_storage.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for each_item in data['data']:\n",
    "    each_item.update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacca8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_of_structure(src, participant_id):\n",
    "    \n",
    "    if os.path.exists(src+'/Video/827000'):\n",
    "        print(f'Folder Exists 827000 in {participant_id}')\n",
    "        # preparing_folder(src+f'/Video/827000')\n",
    "        \n",
    "    elif os.path.exists(src+'/Video/984'):\n",
    "        print(f'Folder Exists 984 in {participant_id}')\n",
    "        # preparing_folder(src+f'/Video/984')\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "All_drivers = os.listdir('Z:/VIDEOS/')\n",
    "for each_driver in All_drivers:\n",
    "    src = f'Z:/VIDEOS/{each_driver}'\n",
    "    validation_of_structure(src, each_driver)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe2fb9a6",
   "metadata": {},
   "source": [
    "### Uploading Data to HPC Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "\n",
    "\n",
    "# def transferFilesToServer(src, dest):\n",
    "#     # files = glob.glob(src, recursive=True)\n",
    "#     # for root, dirs, files in os.walk(src):\n",
    "#     #     root = \"/\".join(root.split('\\\\'))\n",
    "#     #     after_root = \"/\".join(root.split('/')[3:])\n",
    "#     #     for each_dir in dirs:\n",
    "#     #         if os.path.exists(dest+after_root+each_dir):\n",
    "#     #             continue\n",
    "#     #         else:\n",
    "#     #             os.umask(0)\n",
    "                \n",
    "#     #             os.mkdir(dest+after_root+'/'+each_dir, mode=0o777)\n",
    "        \n",
    "#     #     for file in files:\n",
    "#     #         shutil.copy(root+'/'+file, dest+after_root+'/')\n",
    "        \n",
    "#     return f'Total File : {print(len(os.listdir(dest)))}'\n",
    "\n",
    "def transferFilesToServer(src, dst):\n",
    "    print('Started copying the files...')\n",
    "    copy_tree(src, dst)\n",
    "    return 'All files copied successfully'\n",
    "\n",
    "# No '/' at end of src\n",
    "def validation_of_structure(src, participant_id):\n",
    "    \n",
    "    if os.path.exists(src+'/Video/827000'):\n",
    "        print(f'Folder Exists 827000')\n",
    "        preparing_folder(src+f'/Video/827000')\n",
    "        \n",
    "        os.mkdir(f'K:/Backup/{participant_id}')\n",
    "    elif os.path.exists(src+'/Video/984'):\n",
    "        print(f'Folder Exists 984')\n",
    "        preparing_folder(src+f'/Video/984')\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def preparing_folder(src):\n",
    "    print(f'Formatting the folder structure for Source: {src}')\n",
    "    \n",
    "    dest = \"/\".join(src.split('/')[:-1])\n",
    "    print(f'Destination Folder: {dest}')\n",
    "    \n",
    "    copy_tree(src, dest)\n",
    "    \n",
    "    # make backup and transfer files\n",
    "    copy_tree(src, 'K:/Backup/')\n",
    "    print(f'Completed the formatting of folder structure for {src}')\n",
    "\n",
    "# src = 'K:/Videos/1040/'\n",
    "# dest = 'K:/Z/1122/'\n",
    "\n",
    "source = 'K:/Videos/1001'\n",
    "destination = 'Z:/1001'\n",
    "participant_id = '1001'\n",
    " \n",
    "#  this restructure the folders to same as on server\n",
    "# 984/827000 still exists - delete manually\n",
    "validation_of_structure(source, participant_id)\n",
    "\n",
    "# transfer the file to hpc server\n",
    "transferFilesToServer(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a581b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.exists('K:/Z/1022/Video/2021-11-06/T084931000000.asf')\n",
    "# copy_tree(source, destination,)\n",
    "\n",
    "shutil.rmtree('k:/Z/1122/Video/2021-11-02')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a56290a",
   "metadata": {},
   "source": [
    "### Splitting of Driver files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ca1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def gender_stats_from_txtFile(file):\n",
    "    gender_list = {'male': 0, 'female':0, 'None':0}\n",
    "    with open(file) as f:\n",
    "        list_of_files = json.load(f)\n",
    "    for file in list_of_files:\n",
    "        for file, gender in file.items():\n",
    "            gender_list[gender] += 1\n",
    "    # print(f\"Total Stats: {gender_list}\")\n",
    "    return gender_list\n",
    "\n",
    "# g_rest = gender_stats_from_txtFile('gender_deepface_1013_1014.json')\n",
    "# g_1000 = gender_stats_from_txtFile('gender_deepface_1013_1014.txt')\n",
    "\n",
    "gender_stats_from_txtFile('gender_1013_1014.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c62bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two json files and save it to a new file\n",
    "def combine_two_list(list1, list2):\n",
    "    return list1 + list2\n",
    "\n",
    "with open('gender_deepface_1013_1014.json') as f1:\n",
    "    l1 = json.load(f1)\n",
    "\n",
    "\n",
    "with open('gender_deepface_1013_1014.txt') as f2:\n",
    "    l2 = json.load(f2)\n",
    "\n",
    "combined_list = combine_two_list(l1, l2)\n",
    "\n",
    "with open('gender_1013_1014.txt', 'w') as f:\n",
    "    json.dump(combined_list, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tinytag import TinyTag\n",
    "path = 'Z:/VIDEOS/1013_male/Video/'\n",
    "length = len(glob.glob(path+'**/*000.asf'))\n",
    "\n",
    "\n",
    "def get_meta(path):\n",
    "    \n",
    "    # path = os.path.join(path, file)\n",
    "    video = TinyTag.get(path)\n",
    "    video_dict = {\"album\" : video.album,\n",
    "                  \"albumartist\": video.albumartist,\n",
    "                  \"artist\" : video.artist,\n",
    "                  \"aurdio_offset\": video.audio_offset,\n",
    "                  \"bitrate\" : video.bitrate,\n",
    "                  \"comment\" : video.comment,\n",
    "                  \"composer\" : video.composer,\n",
    "                  \"disc\" : video.disc,\n",
    "                  \"disc_total\" : video.disc_total,\n",
    "                  \"duration\" : video.duration,\n",
    "                  \"filesize\" : video.filesize,\n",
    "                  \"genre\" :video.genre,\n",
    "                  \"samplerate\" : video.samplerate,\n",
    "                  \"title\" : video.title,\n",
    "                  \"track\" : video.track,\n",
    "                  \"track_total\" : video.track_total,\n",
    "                  \"year\" : video.year}\n",
    "\n",
    "    # with open('indices.json', 'w') as json_file:\n",
    "    #     json.dump(dict(video_dict), json_file)\n",
    "    return video_dict\n",
    "\n",
    "def get_duration_modified(path):\n",
    "    f_dict = {}\n",
    "    # Glob - getting list of files\n",
    "    counter = 0\n",
    "    total_fileList = len(glob.glob(path+'**/*000.asf'))\n",
    "    \n",
    "    for file in glob.glob(path+'**/*000.asf'):\n",
    "        dur = 0\n",
    "        file = file.replace('\\\\', '/')\n",
    "        metas = get_meta(file)\n",
    "        try:\n",
    "            if metas['duration'] < 10000:\n",
    "                # print(f'Duration: {metas[\"duration\"]}')\n",
    "                dur += int(metas['duration'])\n",
    "        except:\n",
    "            dur += 0\n",
    "            print(f'get_duration()::Error During Processing: {file}')\n",
    "        dir_split = \"\".join(file.split(\"/\")[-1].split(\"-\"))\n",
    "        print(f'Processing : {counter}/{total_fileList}, File: {dir_split}')\n",
    "        counter += 1\n",
    "        print(f_dict)\n",
    "        f_dict[dir_split] = dur\n",
    "    \n",
    "    return f_dict\n",
    "\n",
    "get_duration_modified(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecbeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "telematic_data = pd.read_excel(\"./Data _for_Integration.xlsx\")\n",
    "telematic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab244726",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in telematic_data.iterrows():\n",
    "    print(row[1]['PID'])\n",
    "    print(row[1]['trip start'])\n",
    "    print(row[1]['trip end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "telematic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9175b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "telematic_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d916cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data = [\n",
    "#     {\"id\": \"1001\", \"day\": \"20210920\", \"duration\": 35.86, \"yawn\": {\"total\": 0, \"timestamp\": []}, \"smoking\": {\"total\": 1, \"timestamp\": [\"20210920103721\"]}, \"mobilephone\": {\"total\": 0, \"timestamp\": []}, \"distraction\": {\"total\": 0, \"timestamp\": []}, \"eyeclosing\": {\"total\": 0, \"timestamp\": []}, \"crossinglane\": {\"total\": 0, \"timestamp\": []}, \"nearcollision\": {\"total\": 0, \"timestamp\": []}, \"stopsign\": {\"total\": 0, \"timestamp\": []}, \"redlight\": {\"total\": 0, \"timestamp\": []}, \"pedestrian\": {\"total\": 0, \"timestamp\": []}},\n",
    "#     {\"id\": \"1001\", \"day\": \"20210921\", \"duration\": 39.76, \"yawn\": {\"total\": 0, \"timestamp\": []}, \"smoking\": {\"total\": 1, \"timestamp\": [\"20210921103001\"]}, \"mobilephone\": {\"total\": 0, \"timestamp\": []}, \"distraction\": {\"total\": 0, \"timestamp\": []}, \"eyeclosing\": {\"total\": 0, \"timestamp\": []}, \"crossinglane\": {\"total\": 0, \"timestamp\": []}, \"nearcollision\": {\"total\": 0, \"timestamp\": []}, \"stopsign\": {\"total\": 0, \"timestamp\": []}, \"redlight\": {\"total\": 0, \"timestamp\": []}, \"pedestrian\": {\"total\": 0, \"timestamp\": []}},\n",
    "#     {\"id\": \"1001\", \"day\": \"20230401\", \"duration\": 71.53, \"yawn\": {\"total\": 0, \"timestamp\": []}, \"smoking\": {\"total\": 14, \"timestamp\": [\"20230401122415\", \"20230401122734\", \"20230401123008\", \"20230401123037\", \"20230401123201\", \"20230401124432\", \"20230401125501\", \"20230401183050\", \"20230401183141\", \"20230401183320\", \"20230401183333\", \"20230401184319\", \"20230401184722\", \"20230401190215\"]}, \"mobilephone\": {\"total\": 0, \"timestamp\": []}, \"distraction\": {\"total\": 0, \"timestamp\": []}, \"eyeclosing\": {\"total\": 1, \"timestamp\": [\"20230401185357\"]}, \"crossinglane\": {\"total\": 12, \"timestamp\": [\"20230401124329\", \"20230401124528\", \"20230401124012\", \"20230401125254\", \"20230401183051\", \"20230401183728\", \"20230401183837\", \"20230401185150\", \"20230401185438\", \"20230401185453\", \"20230401183557\", \"20230401185005\"]}, \"nearcollision\": {\"total\": 0, \"timestamp\": []}, \"stopsign\": {\"total\": 0, \"timestamp\": []}, \"redlight\": {\"total\": 0, \"timestamp\": []}, \"pedestrian\": {\"total\": 0, \"timestamp\": []}}\n",
    "# ]\n",
    "with open('data_storage.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "flat_data = []\n",
    "\n",
    "for entry in data['data']:\n",
    "    id_value = entry[\"id\"]\n",
    "    day = entry[\"day\"]\n",
    "    for key, value in entry.items():\n",
    "        if key not in [\"id\", \"day\", \"duration\"]:\n",
    "            if isinstance(value, dict):\n",
    "                total = value[\"total\"]\n",
    "                timestamps = value[\"timestamp\"]\n",
    "                for timestamp in timestamps:\n",
    "                    flat_data.append({\"id\": id_value, \"day\": day, \"type\": key, \"timestamp\": timestamp})\n",
    "\n",
    "df = pd.DataFrame(flat_data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91155678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('video_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb452c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "# Load telematics data\n",
    "telematics_data = pd.read_excel('Data_for_Integration.xlsx')\n",
    "\n",
    "# Convert trip start and trip end columns to datetime\n",
    "telematics_data['trip start'] = pd.to_datetime(telematics_data['trip start'])\n",
    "telematics_data['trip end'] = pd.to_datetime(telematics_data['trip end'])\n",
    "\n",
    "# Load video data from Excel file\n",
    "video_data = pd.read_excel('video_data.xlsx')\n",
    "\n",
    "# Convert the 'timestamp' column to datetime from the 'yyyymmddhhmmss' format\n",
    "video_data['timestamp'] = pd.to_datetime(video_data['timestamp'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Merge based on PID, day, and timestamp\n",
    "merged_data = pd.merge(telematics_data, video_data, how='left', left_on=['PID', 'trip start', 'trip end'], right_on=['id', 'day', 'timestamp'])\n",
    "\n",
    "# Drop redundant columns\n",
    "merged_data = merged_data.drop(['id', 'day', 'timestamp'], axis=1)\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv('merged_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load telematics data\n",
    "telematics_data = pd.read_excel('Data_for_Integration.xlsx')\n",
    "\n",
    "# Convert trip start and trip end columns to datetime\n",
    "telematics_data['trip start'] = pd.to_datetime(telematics_data['trip start'])\n",
    "telematics_data['trip end'] = pd.to_datetime(telematics_data['trip end'])\n",
    "\n",
    "# Load video data from Excel file\n",
    "video_data = pd.read_excel('video_data.xlsx')\n",
    "\n",
    "# Convert the 'timestamp' column to datetime from the 'yyyymmddhhmmss' format\n",
    "video_data['timestamp'] = pd.to_datetime(video_data['timestamp'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Merge based on 'id' and 'day'\n",
    "merged_data = pd.merge(telematics_data, video_data, how='left', left_on=['PID', 'trip start', 'trip end'], right_on=['id', 'day'])\n",
    "\n",
    "# Filter the merged data based on timestamp\n",
    "merged_data = merged_data[(merged_data['timestamp'] >= merged_data['trip start']) & (merged_data['timestamp'] <= merged_data['trip end'])]\n",
    "\n",
    "# Drop redundant columns\n",
    "merged_data = merged_data.drop(['timestamp', 'day', 'id'], axis=1)\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c106316",
   "metadata": {},
   "outputs": [],
   "source": [
    "telematics_data = pd.read_excel('Data_for_Integration.xlsx')\n",
    "# Convert 'trip start' and 'trip end' columns to datetime\n",
    "telematics_data['trip start'] = pd.to_datetime(telematics_data['trip start'])\n",
    "telematics_data['trip end'] = pd.to_datetime(telematics_data['trip end'])\n",
    "\n",
    "# Convert to the desired format\n",
    "telematics_data['trip start formatted'] = telematics_data['trip start'].apply(lambda x: x.strftime('%Y%m%d%H%M%S'))\n",
    "telematics_data['trip end formatted'] = telematics_data['trip end'].apply(lambda x: x.strftime('%Y%m%d%H%M%S'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a346bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "telematics_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc11d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "telematics_data.to_excel('telematic_data_formatted.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video data from Excel file\n",
    "video_data = pd.read_excel('video_data.xlsx')\n",
    "\n",
    "# Convert the 'timestamp' column to datetime from the 'yyyymmddhhmmss' format\n",
    "video_data['timestamp'] = pd.to_datetime(video_data['timestamp'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Merge based on 'id' and 'day'\n",
    "merged_data = pd.merge(telematics_data, video_data, how='left', left_on=['PID', 'trip start formatted', 'trip end formatted'], right_on=['id', 'day', 'timestamp'])\n",
    "\n",
    "# Filter the merged data based on timestamp\n",
    "filtered_data = merged_data[(merged_data['timestamp'] >= merged_data['trip start']) & (merged_data['timestamp'] <= merged_data['trip end'])]\n",
    "\n",
    "# Aggregate data (you can use your own aggregation functions)\n",
    "aggregated_data = filtered_data.groupby(['PID', 'trip start', 'trip end'], as_index=False).agg({\n",
    "    'smoking': 'sum',\n",
    "    'mobilephone': 'sum',\n",
    "    # Add other columns and aggregation functions as needed\n",
    "})\n",
    "\n",
    "# # Merge the aggregated data back to telematics_data\n",
    "# final_data = pd.merge(telematics_data, aggregated_data, how='left', on=['PID', 'trip start', 'trip end'])\n",
    "\n",
    "# # Save the final merged data to a new CSV file\n",
    "# final_data.to_csv('final_merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "video_data = pd.read_excel('video_data.xlsx')\n",
    "trip_data = pd.read_excel('telematic_data_formatted.xlsx')\n",
    "\n",
    "# Convert timestamp columns to datetime format\n",
    "video_data['timestamp'] = pd.to_datetime(video_data['timestamp'], format='%Y%m%d%H%M%S')\n",
    "trip_data['trip start formatted'] = pd.to_datetime(trip_data['trip start formatted'], format='%Y%m%d%H%M%S')\n",
    "trip_data['trip end formatted'] = pd.to_datetime(trip_data['trip end formatted'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Create a function to check if a timestamp is within a given interval\n",
    "def check_interval(row):\n",
    "    return video_data[(video_data['timestamp'] >= row['trip start formatted']) & (video_data['timestamp'] <= row['trip end formatted'])].shape[0]\n",
    "\n",
    "# Apply the function to create a new column in trip_data\n",
    "trip_data['count_per_type'] = trip_data.apply(check_interval, axis=1)\n",
    "\n",
    "# Merge the two datasets based on 'id'\n",
    "merged_data = pd.merge(video_data, trip_data, left_on='id', right_on='PID')\n",
    "\n",
    "\n",
    "merged_data.head()\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv('merged_data2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd806045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load telematic and video data\n",
    "telematic_data = pd.read_csv(\"telematicdatafile.csv\")\n",
    "video_data = pd.read_csv(\"videofiledata.csv\")\n",
    "\n",
    "# Merge data frames\n",
    "merged_data = pd.merge(telematic_data, video_data, left_on=['trip start formatted', 'trip end formatted'], right_on=['timestamp'])\n",
    "\n",
    "# Convert timestamps to datetime format\n",
    "merged_data['trip_start'] = pd.to_datetime(merged_data['trip start formatted'], format='%Y%m%d%H%M%S')\n",
    "merged_data['trip_end'] = pd.to_datetime(merged_data['trip end formatted'], format='%Y%m%d%H%M%S')\n",
    "merged_data['timestamp'] = pd.to_datetime(merged_data['timestamp'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Function to count occurrences within a given interval\n",
    "def count_occurrences(row):\n",
    "    interval_data = merged_data[(merged_data['timestamp'] >= row['trip_start']) & (merged_data['timestamp'] <= row['trip_end'])]\n",
    "    occurrences = interval_data['type'].value_counts()\n",
    "    return occurrences\n",
    "\n",
    "# Apply the function to create new columns\n",
    "occurrence_columns = ['nearcollision', 'crossinglane', 'smoking']  # Add more types as needed\n",
    "for col in occurrence_columns:\n",
    "    telematic_data[col + '_count'] = telematic_data.apply(count_occurrences, axis=1)[col]\n",
    "\n",
    "# Save the updated telematic data\n",
    "# telematic_data.to_csv(\"updated_telematic_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "93ff67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "video_data = pd.read_excel('video_data.xlsx')\n",
    "trip_data = pd.read_excel('telematic_data_formatted.xlsx')\n",
    "\n",
    "# Convert timestamp columns to datetime format\n",
    "video_data['timestamp'] = pd.to_datetime(video_data['timestamp'], format='%Y%m%d%H%M%S')\n",
    "trip_data['trip start formatted'] = pd.to_datetime(trip_data['trip start formatted'], format='%Y%m%d%H%M%S')\n",
    "trip_data['trip end formatted'] = pd.to_datetime(trip_data['trip end formatted'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Create a function to check if a timestamp is within a given interval\n",
    "def check_interval(row):\n",
    "    total = video_data[(video_data['timestamp'] >= row['trip start formatted']) & (video_data['timestamp'] <= row['trip end formatted'])]\n",
    "    # return total.shape[0]\n",
    "    return total['type'].value_counts().to_dict()\n",
    "\n",
    "# Apply the function to create a new column in trip_data\n",
    "trip_data['count_per_type'] = trip_data.apply(check_interval, axis=1)\n",
    "\n",
    "# print(trip_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "79f09dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>trip start</th>\n",
       "      <th>trip end</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>dist_per_trip</th>\n",
       "      <th>n_ACC</th>\n",
       "      <th>n_BRK</th>\n",
       "      <th>n_HTURN</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>air_max</th>\n",
       "      <th>fuel_mean</th>\n",
       "      <th>fuel_sd</th>\n",
       "      <th>fuel_max</th>\n",
       "      <th>thro_mean</th>\n",
       "      <th>thro_sd</th>\n",
       "      <th>thro_max</th>\n",
       "      <th>trip start formatted</th>\n",
       "      <th>trip end formatted</th>\n",
       "      <th>count_per_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-01 13:29:00</td>\n",
       "      <td>2022-06-01 13:52:00</td>\n",
       "      <td>1406.443518</td>\n",
       "      <td>15.021497</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>41.478261</td>\n",
       "      <td>34.664456</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.874453</td>\n",
       "      <td>6.067238</td>\n",
       "      <td>87.843137</td>\n",
       "      <td>21.125320</td>\n",
       "      <td>11.471878</td>\n",
       "      <td>60</td>\n",
       "      <td>2022-06-01 13:29:00</td>\n",
       "      <td>2022-06-01 13:52:00</td>\n",
       "      <td>{'crossinglane': 5, 'mobilephone': 4, 'nearcol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-03 14:05:00</td>\n",
       "      <td>2022-06-03 14:13:00</td>\n",
       "      <td>534.734225</td>\n",
       "      <td>2.980678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.875000</td>\n",
       "      <td>26.346252</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>65.926748</td>\n",
       "      <td>5.411885</td>\n",
       "      <td>75.686275</td>\n",
       "      <td>17.794118</td>\n",
       "      <td>3.636336</td>\n",
       "      <td>23.921569</td>\n",
       "      <td>2022-06-03 14:05:00</td>\n",
       "      <td>2022-06-03 14:13:00</td>\n",
       "      <td>{'crossinglane': 4, 'smoking': 1, 'eyeclosing'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-03 14:48:00</td>\n",
       "      <td>2022-06-03 14:56:00</td>\n",
       "      <td>455.779298</td>\n",
       "      <td>3.151665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>25.332080</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>67.816993</td>\n",
       "      <td>6.458640</td>\n",
       "      <td>80.784314</td>\n",
       "      <td>17.254902</td>\n",
       "      <td>2.780879</td>\n",
       "      <td>21.176471</td>\n",
       "      <td>2022-06-03 14:48:00</td>\n",
       "      <td>2022-06-03 14:56:00</td>\n",
       "      <td>{'crossinglane': 37, 'eyeclosing': 6, 'nearcol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-06 09:42:00</td>\n",
       "      <td>2022-06-06 09:48:00</td>\n",
       "      <td>376.179314</td>\n",
       "      <td>2.388888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>39.050822</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.180599</td>\n",
       "      <td>3.986904</td>\n",
       "      <td>73.725490</td>\n",
       "      <td>17.647059</td>\n",
       "      <td>3.166530</td>\n",
       "      <td>22.745098</td>\n",
       "      <td>2022-06-06 09:42:00</td>\n",
       "      <td>2022-06-06 09:48:00</td>\n",
       "      <td>{'crossinglane': 2, 'smoking': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-06 10:33:00</td>\n",
       "      <td>2022-06-06 10:42:00</td>\n",
       "      <td>560.031980</td>\n",
       "      <td>2.940182</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>18.875028</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.345811</td>\n",
       "      <td>5.569042</td>\n",
       "      <td>81.960784</td>\n",
       "      <td>16.431373</td>\n",
       "      <td>1.871154</td>\n",
       "      <td>18.431373</td>\n",
       "      <td>2022-06-06 10:33:00</td>\n",
       "      <td>2022-06-06 10:42:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID          trip start            trip end  travel_time  \\\n",
       "0  1009 1010 2022-06-01 13:29:00 2022-06-01 13:52:00  1406.443518   \n",
       "1  1009 1010 2022-06-03 14:05:00 2022-06-03 14:13:00   534.734225   \n",
       "2  1009 1010 2022-06-03 14:48:00 2022-06-03 14:56:00   455.779298   \n",
       "3  1009 1010 2022-06-06 09:42:00 2022-06-06 09:48:00   376.179314   \n",
       "4  1009 1010 2022-06-06 10:33:00 2022-06-06 10:42:00   560.031980   \n",
       "\n",
       "   dist_per_trip  n_ACC  n_BRK  n_HTURN  speed_mean   speed_sd  ...  air_max  \\\n",
       "0      15.021497      3      3        7   41.478261  34.664456  ...     36.0   \n",
       "1       2.980678      2      0        3   19.875000  26.346252  ...     25.0   \n",
       "2       3.151665      1      1        3   22.500000  25.332080  ...     24.0   \n",
       "3       2.388888      1      1        2   25.166667  39.050822  ...     33.0   \n",
       "4       2.940182      2      1        2   10.600000  18.875028  ...     38.0   \n",
       "\n",
       "   fuel_mean   fuel_sd   fuel_max  thro_mean    thro_sd   thro_max  \\\n",
       "0  69.874453  6.067238  87.843137  21.125320  11.471878         60   \n",
       "1  65.926748  5.411885  75.686275  17.794118   3.636336  23.921569   \n",
       "2  67.816993  6.458640  80.784314  17.254902   2.780879  21.176471   \n",
       "3  65.180599  3.986904  73.725490  17.647059   3.166530  22.745098   \n",
       "4  66.345811  5.569042  81.960784  16.431373   1.871154  18.431373   \n",
       "\n",
       "   trip start formatted  trip end formatted  \\\n",
       "0   2022-06-01 13:29:00 2022-06-01 13:52:00   \n",
       "1   2022-06-03 14:05:00 2022-06-03 14:13:00   \n",
       "2   2022-06-03 14:48:00 2022-06-03 14:56:00   \n",
       "3   2022-06-06 09:42:00 2022-06-06 09:48:00   \n",
       "4   2022-06-06 10:33:00 2022-06-06 10:42:00   \n",
       "\n",
       "                                      count_per_type  \n",
       "0  {'crossinglane': 5, 'mobilephone': 4, 'nearcol...  \n",
       "1  {'crossinglane': 4, 'smoking': 1, 'eyeclosing'...  \n",
       "2  {'crossinglane': 37, 'eyeclosing': 6, 'nearcol...  \n",
       "3                  {'crossinglane': 2, 'smoking': 1}  \n",
       "4                                                 {}  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming trip_data is your telematic data DataFrame\n",
    "# Load telematic and video data into DataFrames\n",
    "# Read the CSV files\n",
    "video_data = pd.read_excel('video_data.xlsx')\n",
    "trip_data = pd.read_excel('telematic_data_formatted.xlsx')\n",
    "\n",
    "# Merge DataFrames based on timestamp\n",
    "merged_data = pd.merge(telematic_data, video_data, left_on=\"trip start formatted\", right_on=\"timestamp\", how=\"left\")\n",
    "\n",
    "# Create a function to check if a timestamp is within a given interval\n",
    "def check_interval(row):\n",
    "    total = video_data[(video_data['timestamp'] >= row['trip start formatted']) & (video_data['timestamp'] <= row['trip end formatted'])]\n",
    "    return total['type'].value_counts().to_dict()\n",
    "\n",
    "# Apply the function to create a new column in telematic_data\n",
    "telematic_data['count_per_type'] = telematic_data.apply(check_interval, axis=1)\n",
    "\n",
    "# Expand the dictionary into separate columns\n",
    "count_per_type_df = telematic_data['count_per_type'].apply(pd.Series)\n",
    "\n",
    "# Merge the expanded data back to the original telematic DataFrame\n",
    "final_data = pd.concat([telematic_data, count_per_type_df], axis=1)\n",
    "\n",
    "# Drop the original 'count_per_type' column if needed\n",
    "final_data = final_data.drop('count_per_type', axis=1)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "final_data = final_data.fillna(0)\n",
    "\n",
    "# Print or use the final DataFrame as needed\n",
    "print(final_data)\n",
    "\n",
    "pd.to_excel('final_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e4719891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/.pyenv/versions/3.7.16/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>trip start</th>\n",
       "      <th>trip end</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>dist_per_trip</th>\n",
       "      <th>n_ACC</th>\n",
       "      <th>n_BRK</th>\n",
       "      <th>n_HTURN</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>air_max</th>\n",
       "      <th>fuel_mean</th>\n",
       "      <th>fuel_sd</th>\n",
       "      <th>fuel_max</th>\n",
       "      <th>thro_mean</th>\n",
       "      <th>thro_sd</th>\n",
       "      <th>thro_max</th>\n",
       "      <th>trip start formatted</th>\n",
       "      <th>trip end formatted</th>\n",
       "      <th>count_per_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-01 13:29:00</td>\n",
       "      <td>2022-06-01 13:52:00</td>\n",
       "      <td>1406.443518</td>\n",
       "      <td>15.021497</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>41.478261</td>\n",
       "      <td>34.664456</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.874453</td>\n",
       "      <td>6.067238</td>\n",
       "      <td>87.843137</td>\n",
       "      <td>21.125320</td>\n",
       "      <td>11.471878</td>\n",
       "      <td>60</td>\n",
       "      <td>20220601132900</td>\n",
       "      <td>20220601135200</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-03 14:05:00</td>\n",
       "      <td>2022-06-03 14:13:00</td>\n",
       "      <td>534.734225</td>\n",
       "      <td>2.980678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.875000</td>\n",
       "      <td>26.346252</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>65.926748</td>\n",
       "      <td>5.411885</td>\n",
       "      <td>75.686275</td>\n",
       "      <td>17.794118</td>\n",
       "      <td>3.636336</td>\n",
       "      <td>23.921569</td>\n",
       "      <td>20220603140500</td>\n",
       "      <td>20220603141300</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-03 14:48:00</td>\n",
       "      <td>2022-06-03 14:56:00</td>\n",
       "      <td>455.779298</td>\n",
       "      <td>3.151665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>25.332080</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>67.816993</td>\n",
       "      <td>6.458640</td>\n",
       "      <td>80.784314</td>\n",
       "      <td>17.254902</td>\n",
       "      <td>2.780879</td>\n",
       "      <td>21.176471</td>\n",
       "      <td>20220603144800</td>\n",
       "      <td>20220603145600</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-06 09:42:00</td>\n",
       "      <td>2022-06-06 09:48:00</td>\n",
       "      <td>376.179314</td>\n",
       "      <td>2.388888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>39.050822</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.180599</td>\n",
       "      <td>3.986904</td>\n",
       "      <td>73.725490</td>\n",
       "      <td>17.647059</td>\n",
       "      <td>3.166530</td>\n",
       "      <td>22.745098</td>\n",
       "      <td>20220606094200</td>\n",
       "      <td>20220606094800</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-06 10:33:00</td>\n",
       "      <td>2022-06-06 10:42:00</td>\n",
       "      <td>560.031980</td>\n",
       "      <td>2.940182</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>18.875028</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.345811</td>\n",
       "      <td>5.569042</td>\n",
       "      <td>81.960784</td>\n",
       "      <td>16.431373</td>\n",
       "      <td>1.871154</td>\n",
       "      <td>18.431373</td>\n",
       "      <td>20220606103300</td>\n",
       "      <td>20220606104200</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID           trip start             trip end  travel_time  \\\n",
       "0  1009 1010  2022-06-01 13:29:00  2022-06-01 13:52:00  1406.443518   \n",
       "1  1009 1010  2022-06-03 14:05:00  2022-06-03 14:13:00   534.734225   \n",
       "2  1009 1010  2022-06-03 14:48:00  2022-06-03 14:56:00   455.779298   \n",
       "3  1009 1010  2022-06-06 09:42:00  2022-06-06 09:48:00   376.179314   \n",
       "4  1009 1010  2022-06-06 10:33:00  2022-06-06 10:42:00   560.031980   \n",
       "\n",
       "   dist_per_trip  n_ACC  n_BRK  n_HTURN  speed_mean   speed_sd  ...  air_max  \\\n",
       "0      15.021497      3      3        7   41.478261  34.664456  ...     36.0   \n",
       "1       2.980678      2      0        3   19.875000  26.346252  ...     25.0   \n",
       "2       3.151665      1      1        3   22.500000  25.332080  ...     24.0   \n",
       "3       2.388888      1      1        2   25.166667  39.050822  ...     33.0   \n",
       "4       2.940182      2      1        2   10.600000  18.875028  ...     38.0   \n",
       "\n",
       "   fuel_mean   fuel_sd   fuel_max  thro_mean    thro_sd   thro_max  \\\n",
       "0  69.874453  6.067238  87.843137  21.125320  11.471878         60   \n",
       "1  65.926748  5.411885  75.686275  17.794118   3.636336  23.921569   \n",
       "2  67.816993  6.458640  80.784314  17.254902   2.780879  21.176471   \n",
       "3  65.180599  3.986904  73.725490  17.647059   3.166530  22.745098   \n",
       "4  66.345811  5.569042  81.960784  16.431373   1.871154  18.431373   \n",
       "\n",
       "   trip start formatted  trip end formatted  count_per_type  \n",
       "0        20220601132900      20220601135200              {}  \n",
       "1        20220603140500      20220603141300              {}  \n",
       "2        20220603144800      20220603145600              {}  \n",
       "3        20220606094200      20220606094800              {}  \n",
       "4        20220606103300      20220606104200              {}  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "video_data = pd.read_csv('video_csv.csv')\n",
    "trip_data = pd.read_csv('telematics_csv.csv')\n",
    "\n",
    "# Convert timestamp columns to datetime format\n",
    "# video_data['timestamp'] = pd.to_datetime(video_data['timestamp'], format='%Y%m%d%H%M%S')\n",
    "# trip_data['trip start formatted'] = pd.to_datetime(trip_data['trip start formatted'], format='%Y%m%d%H%M%S')\n",
    "# trip_data['trip end formatted'] = pd.to_datetime(trip_data['trip end formatted'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Create a function to check if a timestamp is within a given interval\n",
    "def check_interval(row):\n",
    "    total = video_data[(video_data['id'] == row['PID']) & (video_data['timestamp'] >= row['trip start formatted']) & (video_data['timestamp'] <= row['trip end formatted'])]\n",
    "    # print(total['type'].value_counts())\n",
    "    # print(total['type'].value_counts().to_dict())\n",
    "    return total['type'].value_counts().to_dict()\n",
    "\n",
    "# Apply the function to create a new column in trip_data\n",
    "trip_data['count_per_type'] = trip_data.apply(check_interval, axis=1)\n",
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1272cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.to_csv('trip_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7755e544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>trip start</th>\n",
       "      <th>trip end</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>dist_per_trip</th>\n",
       "      <th>n_ACC</th>\n",
       "      <th>n_BRK</th>\n",
       "      <th>n_HTURN</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>air_max</th>\n",
       "      <th>fuel_mean</th>\n",
       "      <th>fuel_sd</th>\n",
       "      <th>fuel_max</th>\n",
       "      <th>thro_mean</th>\n",
       "      <th>thro_sd</th>\n",
       "      <th>thro_max</th>\n",
       "      <th>trip start formatted</th>\n",
       "      <th>trip end formatted</th>\n",
       "      <th>count_per_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-01 13:29:00</td>\n",
       "      <td>2022-06-01 13:52:00</td>\n",
       "      <td>1406.443518</td>\n",
       "      <td>15.021497</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>41.478261</td>\n",
       "      <td>34.664456</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.874453</td>\n",
       "      <td>6.067238</td>\n",
       "      <td>87.843137</td>\n",
       "      <td>21.125320</td>\n",
       "      <td>11.471878</td>\n",
       "      <td>60</td>\n",
       "      <td>2022-06-01 13:29:00</td>\n",
       "      <td>2022-06-01 13:52:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-03 14:05:00</td>\n",
       "      <td>2022-06-03 14:13:00</td>\n",
       "      <td>534.734225</td>\n",
       "      <td>2.980678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.875000</td>\n",
       "      <td>26.346252</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>65.926748</td>\n",
       "      <td>5.411885</td>\n",
       "      <td>75.686275</td>\n",
       "      <td>17.794118</td>\n",
       "      <td>3.636336</td>\n",
       "      <td>23.921569</td>\n",
       "      <td>2022-06-03 14:05:00</td>\n",
       "      <td>2022-06-03 14:13:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-03 14:48:00</td>\n",
       "      <td>2022-06-03 14:56:00</td>\n",
       "      <td>455.779298</td>\n",
       "      <td>3.151665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>25.332080</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>67.816993</td>\n",
       "      <td>6.458640</td>\n",
       "      <td>80.784314</td>\n",
       "      <td>17.254902</td>\n",
       "      <td>2.780879</td>\n",
       "      <td>21.176471</td>\n",
       "      <td>2022-06-03 14:48:00</td>\n",
       "      <td>2022-06-03 14:56:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-06 09:42:00</td>\n",
       "      <td>2022-06-06 09:48:00</td>\n",
       "      <td>376.179314</td>\n",
       "      <td>2.388888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>39.050822</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.180599</td>\n",
       "      <td>3.986904</td>\n",
       "      <td>73.725490</td>\n",
       "      <td>17.647059</td>\n",
       "      <td>3.166530</td>\n",
       "      <td>22.745098</td>\n",
       "      <td>2022-06-06 09:42:00</td>\n",
       "      <td>2022-06-06 09:48:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-06 10:33:00</td>\n",
       "      <td>2022-06-06 10:42:00</td>\n",
       "      <td>560.031980</td>\n",
       "      <td>2.940182</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>18.875028</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.345811</td>\n",
       "      <td>5.569042</td>\n",
       "      <td>81.960784</td>\n",
       "      <td>16.431373</td>\n",
       "      <td>1.871154</td>\n",
       "      <td>18.431373</td>\n",
       "      <td>2022-06-06 10:33:00</td>\n",
       "      <td>2022-06-06 10:42:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID          trip start            trip end  travel_time  \\\n",
       "0  1009 1010 2022-06-01 13:29:00 2022-06-01 13:52:00  1406.443518   \n",
       "1  1009 1010 2022-06-03 14:05:00 2022-06-03 14:13:00   534.734225   \n",
       "2  1009 1010 2022-06-03 14:48:00 2022-06-03 14:56:00   455.779298   \n",
       "3  1009 1010 2022-06-06 09:42:00 2022-06-06 09:48:00   376.179314   \n",
       "4  1009 1010 2022-06-06 10:33:00 2022-06-06 10:42:00   560.031980   \n",
       "\n",
       "   dist_per_trip  n_ACC  n_BRK  n_HTURN  speed_mean   speed_sd  ...  air_max  \\\n",
       "0      15.021497      3      3        7   41.478261  34.664456  ...     36.0   \n",
       "1       2.980678      2      0        3   19.875000  26.346252  ...     25.0   \n",
       "2       3.151665      1      1        3   22.500000  25.332080  ...     24.0   \n",
       "3       2.388888      1      1        2   25.166667  39.050822  ...     33.0   \n",
       "4       2.940182      2      1        2   10.600000  18.875028  ...     38.0   \n",
       "\n",
       "   fuel_mean   fuel_sd   fuel_max  thro_mean    thro_sd   thro_max  \\\n",
       "0  69.874453  6.067238  87.843137  21.125320  11.471878         60   \n",
       "1  65.926748  5.411885  75.686275  17.794118   3.636336  23.921569   \n",
       "2  67.816993  6.458640  80.784314  17.254902   2.780879  21.176471   \n",
       "3  65.180599  3.986904  73.725490  17.647059   3.166530  22.745098   \n",
       "4  66.345811  5.569042  81.960784  16.431373   1.871154  18.431373   \n",
       "\n",
       "   trip start formatted  trip end formatted  count_per_type  \n",
       "0   2022-06-01 13:29:00 2022-06-01 13:52:00              {}  \n",
       "1   2022-06-03 14:05:00 2022-06-03 14:13:00              {}  \n",
       "2   2022-06-03 14:48:00 2022-06-03 14:56:00              {}  \n",
       "3   2022-06-06 09:42:00 2022-06-06 09:48:00              {}  \n",
       "4   2022-06-06 10:33:00 2022-06-06 10:42:00              {}  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "video_data = pd.read_excel('video_data.xlsx')\n",
    "trip_data = pd.read_excel('telematic_data_formatted.xlsx')\n",
    "\n",
    "# Convert timestamp columns to datetime format\n",
    "video_data['timestamp'] = pd.to_datetime(video_data['timestamp'], format='%Y%m%d%H%M%S')\n",
    "trip_data['trip start formatted'] = pd.to_datetime(trip_data['trip start formatted'], format='%Y%m%d%H%M%S')\n",
    "trip_data['trip end formatted'] = pd.to_datetime(trip_data['trip end formatted'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Create a function to check if a timestamp is within a given interval\n",
    "def check_interval(row):\n",
    "    total = video_data[(video_data['id'] == row['PID']) & (video_data['timestamp'] >= row['trip start formatted']) & (video_data['timestamp'] <= row['trip end formatted'])]\n",
    "    # print(total['type'].value_counts())\n",
    "    # print(total['type'].value_counts().to_dict())\n",
    "    return total['type'].value_counts().to_dict()\n",
    "\n",
    "# Apply the function to create a new column in trip_data\n",
    "trip_data['count_per_type'] = trip_data.apply(check_interval, axis=1)\n",
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c990c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.to_excel('final_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ac7cf349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>trip start</th>\n",
       "      <th>trip end</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>dist_per_trip</th>\n",
       "      <th>n_ACC</th>\n",
       "      <th>n_BRK</th>\n",
       "      <th>n_HTURN</th>\n",
       "      <th>speed_mean</th>\n",
       "      <th>speed_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>air_sd</th>\n",
       "      <th>air_max</th>\n",
       "      <th>fuel_mean</th>\n",
       "      <th>fuel_sd</th>\n",
       "      <th>fuel_max</th>\n",
       "      <th>thro_mean</th>\n",
       "      <th>thro_sd</th>\n",
       "      <th>thro_max</th>\n",
       "      <th>trip start formatted</th>\n",
       "      <th>trip end formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-01 13:29:00</td>\n",
       "      <td>2022-06-01 13:52:00</td>\n",
       "      <td>1406.443518</td>\n",
       "      <td>15.021497</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>41.478261</td>\n",
       "      <td>34.664456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.278374</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.874453</td>\n",
       "      <td>6.067238</td>\n",
       "      <td>87.843137</td>\n",
       "      <td>21.125320</td>\n",
       "      <td>11.471878</td>\n",
       "      <td>60</td>\n",
       "      <td>20220601132900</td>\n",
       "      <td>20220601135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-03 14:05:00</td>\n",
       "      <td>2022-06-03 14:13:00</td>\n",
       "      <td>534.734225</td>\n",
       "      <td>2.980678</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.875000</td>\n",
       "      <td>26.346252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409432</td>\n",
       "      <td>25.0</td>\n",
       "      <td>65.926748</td>\n",
       "      <td>5.411885</td>\n",
       "      <td>75.686275</td>\n",
       "      <td>17.794118</td>\n",
       "      <td>3.636336</td>\n",
       "      <td>23.921569</td>\n",
       "      <td>20220603140500</td>\n",
       "      <td>20220603141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-03 14:48:00</td>\n",
       "      <td>2022-06-03 14:56:00</td>\n",
       "      <td>455.779298</td>\n",
       "      <td>3.151665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>25.332080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468179</td>\n",
       "      <td>24.0</td>\n",
       "      <td>67.816993</td>\n",
       "      <td>6.458640</td>\n",
       "      <td>80.784314</td>\n",
       "      <td>17.254902</td>\n",
       "      <td>2.780879</td>\n",
       "      <td>21.176471</td>\n",
       "      <td>20220603144800</td>\n",
       "      <td>20220603145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-06 09:42:00</td>\n",
       "      <td>2022-06-06 09:48:00</td>\n",
       "      <td>376.179314</td>\n",
       "      <td>2.388888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>39.050822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780724</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.180599</td>\n",
       "      <td>3.986904</td>\n",
       "      <td>73.725490</td>\n",
       "      <td>17.647059</td>\n",
       "      <td>3.166530</td>\n",
       "      <td>22.745098</td>\n",
       "      <td>20220606094200</td>\n",
       "      <td>20220606094800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009 1010</td>\n",
       "      <td>2022-06-06 10:33:00</td>\n",
       "      <td>2022-06-06 10:42:00</td>\n",
       "      <td>560.031980</td>\n",
       "      <td>2.940182</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>18.875028</td>\n",
       "      <td>...</td>\n",
       "      <td>1.224607</td>\n",
       "      <td>38.0</td>\n",
       "      <td>66.345811</td>\n",
       "      <td>5.569042</td>\n",
       "      <td>81.960784</td>\n",
       "      <td>16.431373</td>\n",
       "      <td>1.871154</td>\n",
       "      <td>18.431373</td>\n",
       "      <td>20220606103300</td>\n",
       "      <td>20220606104200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID           trip start             trip end  travel_time  \\\n",
       "0  1009 1010  2022-06-01 13:29:00  2022-06-01 13:52:00  1406.443518   \n",
       "1  1009 1010  2022-06-03 14:05:00  2022-06-03 14:13:00   534.734225   \n",
       "2  1009 1010  2022-06-03 14:48:00  2022-06-03 14:56:00   455.779298   \n",
       "3  1009 1010  2022-06-06 09:42:00  2022-06-06 09:48:00   376.179314   \n",
       "4  1009 1010  2022-06-06 10:33:00  2022-06-06 10:42:00   560.031980   \n",
       "\n",
       "   dist_per_trip  n_ACC  n_BRK  n_HTURN  speed_mean   speed_sd  ...    air_sd  \\\n",
       "0      15.021497      3      3        7   41.478261  34.664456  ...  1.278374   \n",
       "1       2.980678      2      0        3   19.875000  26.346252  ...  0.409432   \n",
       "2       3.151665      1      1        3   22.500000  25.332080  ...  0.468179   \n",
       "3       2.388888      1      1        2   25.166667  39.050822  ...  0.780724   \n",
       "4       2.940182      2      1        2   10.600000  18.875028  ...  1.224607   \n",
       "\n",
       "   air_max  fuel_mean   fuel_sd   fuel_max  thro_mean    thro_sd   thro_max  \\\n",
       "0     36.0  69.874453  6.067238  87.843137  21.125320  11.471878         60   \n",
       "1     25.0  65.926748  5.411885  75.686275  17.794118   3.636336  23.921569   \n",
       "2     24.0  67.816993  6.458640  80.784314  17.254902   2.780879  21.176471   \n",
       "3     33.0  65.180599  3.986904  73.725490  17.647059   3.166530  22.745098   \n",
       "4     38.0  66.345811  5.569042  81.960784  16.431373   1.871154  18.431373   \n",
       "\n",
       "   trip start formatted  trip end formatted  \n",
       "0        20220601132900      20220601135200  \n",
       "1        20220603140500      20220603141300  \n",
       "2        20220603144800      20220603145600  \n",
       "3        20220606094200      20220606094800  \n",
       "4        20220606103300      20220606104200  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('telematics_csv.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02c0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Conversion of formatted timestamps in json file \n",
    "telematics_data['trip start'] = pd.to_datetime(telematics_data['trip start'])\n",
    "telematics_data['trip end'] = pd.to_datetime(telematics_data['trip end'])\n",
    "\n",
    "# Convert to the desired format\n",
    "telematics_data['trip start formatted'] = telematics_data['trip start'].apply(lambda x: x.strftime('%Y%m%d%H%M%S'))\n",
    "telematics_data['trip end formatted'] = telematics_data['trip end'].apply(lambda x: x.strftime('%Y%m%d%H%M%S'))\n",
    "\n",
    "\n",
    "\n",
    "# Assuming trip_data is your telematic data DataFrame\n",
    "# Load telematic and video data into DataFrames\n",
    "video_data = pd.read_csv('video_csv.csv')\n",
    "trip_data = pd.read_csv('telematics_csv.csv')\n",
    "\n",
    "# Merge DataFrames based on timestamp\n",
    "merged_data = pd.merge(trip_data, video_data, left_on=\"trip start formatted\", right_on=\"timestamp\", how=\"left\")\n",
    "\n",
    "# Create a function to check if a timestamp is within a given interval\n",
    "def check_interval(row):\n",
    "    total = video_data[(video_data['id'] == row['PID']) & (video_data['timestamp'] >= row['trip start formatted']) & (video_data['timestamp'] <= row['trip end formatted'])]\n",
    "    return total['type'].value_counts().to_dict()\n",
    "\n",
    "\n",
    "# Apply the function to create a new column in telematic_data\n",
    "trip_data['count_per_type'] = trip_data.apply(check_interval, axis=1)\n",
    "\n",
    "# Expand the dictionary into separate columns\n",
    "count_per_type_df = trip_data['count_per_type'].apply(pd.Series)\n",
    "\n",
    "# Merge the expanded data back to the original telematic DataFrame\n",
    "final_data = pd.concat([trip_data, count_per_type_df], axis=1)\n",
    "\n",
    "# Drop the original 'count_per_type' column if needed\n",
    "final_data = final_data.drop('count_per_type', axis=1)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "final_data = final_data.fillna(0)\n",
    "\n",
    "# Print or use the final DataFrame as needed\n",
    "final_data.to_csv('Merged_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Driver_indices-DsFqzCcB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5dd92fb0320f6de981139fad36e905da6c43d5f0ca47ced40c32e9f3f500edc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
