{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f6579-19e3-41bd-8460-5ef9f5068658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:/VIDEOS/1119/Videos/ exists\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "if os.path.exists('Y:/VIDEOS/1119/Videos/'):\n",
    "    print('Y:/VIDEOS/1119/Videos/ exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of Folders/Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: .DS_Store, folder: Y:/VIDEOS/.DS_Store/Video/\n",
      "idx: .DS_Store, files: 0\n",
      "idx: 1001, folder: Y:/VIDEOS/1001/Video/\n",
      "idx: 1001, files: 0\n",
      "idx: 1002, folder: Y:/VIDEOS/1002/Video/\n",
      "idx: 1002, files: 0\n",
      "idx: 1003_1004, folder: Y:/VIDEOS/1003_1004/Video/\n",
      "idx: 1003_1004, files: 0\n",
      "idx: 1003_1004-nonAI, folder: Y:/VIDEOS/1003_1004-nonAI/Video/\n",
      "idx: 1003_1004-nonAI, files: 0\n",
      "idx: 1005, folder: Y:/VIDEOS/1005/Video/\n",
      "idx: 1005, files: 0\n",
      "idx: 1005-nonAI, folder: Y:/VIDEOS/1005-nonAI/Video/\n",
      "idx: 1005-nonAI, files: 0\n",
      "idx: 1006, folder: Y:/VIDEOS/1006/Video/\n",
      "idx: 1006, files: 0\n",
      "idx: 1009, folder: Y:/VIDEOS/1009/Video/\n",
      "idx: 1009, files: 0\n",
      "idx: 1009_1010, folder: Y:/VIDEOS/1009_1010/Video/\n",
      "idx: 1009_1010, files: 0\n",
      "idx: 1010, folder: Y:/VIDEOS/1010/Video/\n",
      "idx: 1010, files: 0\n",
      "idx: 1011_1012, folder: Y:/VIDEOS/1011_1012/Video/\n",
      "idx: 1011_1012, files: 0\n",
      "idx: 1013, folder: Y:/VIDEOS/1013/Video/\n",
      "idx: 1013, files: 0\n",
      "idx: 1013_1014, folder: Y:/VIDEOS/1013_1014/Video/\n",
      "idx: 1013_1014, files: 0\n",
      "idx: 1015, folder: Y:/VIDEOS/1015/Video/\n",
      "idx: 1015, files: 0\n",
      "idx: 1017, folder: Y:/VIDEOS/1017/Video/\n",
      "idx: 1017, files: 0\n",
      "idx: 1018, folder: Y:/VIDEOS/1018/Video/\n",
      "idx: 1018, files: 0\n",
      "idx: 1021, folder: Y:/VIDEOS/1021/Video/\n",
      "idx: 1021, files: 0\n",
      "idx: 1022, folder: Y:/VIDEOS/1022/Video/\n",
      "idx: 1022, files: 0\n",
      "idx: 1023, folder: Y:/VIDEOS/1023/Video/\n",
      "idx: 1023, files: 0\n",
      "idx: 1025, folder: Y:/VIDEOS/1025/Video/\n",
      "idx: 1025, files: 0\n",
      "idx: 1027, folder: Y:/VIDEOS/1027/Video/\n",
      "idx: 1027, files: 0\n",
      "idx: 1029, folder: Y:/VIDEOS/1029/Video/\n",
      "idx: 1029, files: 0\n",
      "idx: 1031, folder: Y:/VIDEOS/1031/Video/\n",
      "idx: 1031, files: 0\n",
      "idx: 1031_1017, folder: Y:/VIDEOS/1031_1017/Video/\n",
      "idx: 1031_1017, files: 0\n",
      "idx: 1038, folder: Y:/VIDEOS/1038/Video/\n",
      "idx: 1038, files: 0\n",
      "idx: 1040, folder: Y:/VIDEOS/1040/Video/\n",
      "idx: 1040, files: 0\n",
      "idx: 1041, folder: Y:/VIDEOS/1041/Video/\n",
      "idx: 1041, files: 0\n",
      "idx: 1043  1044, folder: Y:/VIDEOS/1043  1044/Videos/\n",
      "idx: 1043_1044, folder: Y:/VIDEOS/1043_1044/Video/\n",
      "idx: 1043_1044, files: 0\n",
      "idx: 1045, folder: Y:/VIDEOS/1045/Video/\n",
      "idx: 1045, files: 0\n",
      "idx: 1053, folder: Y:/VIDEOS/1053/Videos/\n",
      "idx: 1054, folder: Y:/VIDEOS/1054/Video/\n",
      "idx: 1054, files: 0\n",
      "idx: 1055_1056, folder: Y:/VIDEOS/1055_1056/Video/\n",
      "idx: 1055_1056, files: 0\n",
      "idx: 1056, folder: Y:/VIDEOS/1056/Video/\n",
      "idx: 1056, files: 0\n",
      "idx: 1057, folder: Y:/VIDEOS/1057/Video/\n",
      "idx: 1057, files: 0\n",
      "idx: 1059, folder: Y:/VIDEOS/1059/Videos/\n",
      "idx: 1061, folder: Y:/VIDEOS/1061/Video/\n",
      "idx: 1061, files: 0\n",
      "idx: 1063, folder: Y:/VIDEOS/1063/Video/\n",
      "idx: 1063, files: 0\n",
      "idx: 1064, folder: Y:/VIDEOS/1064/Video/\n",
      "idx: 1064, files: 0\n",
      "idx: 1066, folder: Y:/VIDEOS/1066/Videos/\n",
      "idx: 1067, folder: Y:/VIDEOS/1067/Video/\n",
      "idx: 1067, files: 0\n",
      "idx: 1069, folder: Y:/VIDEOS/1069/Video/\n",
      "idx: 1069, files: 0\n",
      "idx: 1070, folder: Y:/VIDEOS/1070/Video/\n",
      "idx: 1070, files: 0\n",
      "idx: 1072, folder: Y:/VIDEOS/1072/Video/\n",
      "idx: 1072, files: 0\n",
      "idx: 1073, folder: Y:/VIDEOS/1073/Video/\n",
      "idx: 1073, files: 0\n",
      "idx: 1074, folder: Y:/VIDEOS/1074/Video/\n",
      "idx: 1074, files: 0\n",
      "idx: 1074_1075, folder: Y:/VIDEOS/1074_1075/Video/\n",
      "idx: 1074_1075, files: 0\n",
      "idx: 1076, folder: Y:/VIDEOS/1076/Video/\n",
      "idx: 1076, files: 0\n",
      "idx: 1077, folder: Y:/VIDEOS/1077/Video/\n",
      "idx: 1077, files: 0\n",
      "idx: 1078, folder: Y:/VIDEOS/1078/Video/\n",
      "idx: 1078, files: 0\n",
      "idx: 1079, folder: Y:/VIDEOS/1079/Video/\n",
      "idx: 1079, files: 0\n",
      "idx: 1082, folder: Y:/VIDEOS/1082/Video/\n",
      "idx: 1082, files: 0\n",
      "idx: 1083, folder: Y:/VIDEOS/1083/Video/\n",
      "idx: 1083, files: 0\n",
      "idx: 1084, folder: Y:/VIDEOS/1084/Video/\n",
      "idx: 1084, files: 0\n",
      "idx: 1086, folder: Y:/VIDEOS/1086/Video/\n",
      "idx: 1086, files: 0\n",
      "idx: 1087, folder: Y:/VIDEOS/1087/Videos/\n",
      "idx: 1089, folder: Y:/VIDEOS/1089/Video/\n",
      "idx: 1089, files: 0\n",
      "idx: 1094, folder: Y:/VIDEOS/1094/Video/\n",
      "idx: 1094, files: 0\n",
      "idx: 1097, folder: Y:/VIDEOS/1097/Video/\n",
      "idx: 1097, files: 0\n",
      "idx: 1099_1100, folder: Y:/VIDEOS/1099_1100/Video/\n",
      "idx: 1099_1100, files: 0\n",
      "idx: 1101, folder: Y:/VIDEOS/1101/Video/\n",
      "idx: 1101, files: 0\n",
      "idx: 1103, folder: Y:/VIDEOS/1103/Video/\n",
      "idx: 1103, files: 0\n",
      "idx: 1111, folder: Y:/VIDEOS/1111/Video/\n",
      "idx: 1111, files: 0\n",
      "idx: 1114, folder: Y:/VIDEOS/1114/Video/\n",
      "idx: 1114, files: 0\n",
      "idx: 1115, folder: Y:/VIDEOS/1115/Video/\n",
      "idx: 1115, files: 0\n",
      "idx: 1116, folder: Y:/VIDEOS/1116/Video/\n",
      "idx: 1116, files: 0\n",
      "idx: 1118, folder: Y:/VIDEOS/1118/Video/\n",
      "idx: 1118, files: 0\n",
      "idx: 1119, folder: Y:/VIDEOS/1119/Videos/\n",
      "idx: 1123, folder: Y:/VIDEOS/1123/Videos/\n",
      "idx: 1127, folder: Y:/VIDEOS/1127/Video/\n",
      "idx: 1127, files: 0\n",
      "idx: 1129, folder: Y:/VIDEOS/1129/Videos/\n",
      "idx: 2002, folder: Y:/VIDEOS/2002/Video/\n",
      "idx: 2002, files: 0\n",
      "idx: 2037, folder: Y:/VIDEOS/2037/Video/\n",
      "idx: 2037, files: 0\n",
      "idx: 2042, folder: Y:/VIDEOS/2042/Video/\n",
      "idx: 2042, files: 0\n",
      "idx: 2047, folder: Y:/VIDEOS/2047/Video/\n",
      "idx: 2047, files: 0\n",
      "idx: 2050, folder: Y:/VIDEOS/2050/Video/\n",
      "idx: 2050, files: 0\n",
      "idx: 2051, folder: Y:/VIDEOS/2051/Video/\n",
      "idx: 2051, files: 0\n",
      "idx: 2062, folder: Y:/VIDEOS/2062/Video/\n",
      "idx: 2062, files: 0\n",
      "idx: 2065, folder: Y:/VIDEOS/2065/Videos/\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "folder = 'Y:/VIDEOS'\n",
    "\n",
    "ids = os.listdir(folder)\n",
    "excluded_list = []\n",
    "for idx in ids:\n",
    "    \n",
    "    # check folder name\n",
    "    if os.path.exists(folder + '/' + idx + '/Videos/'):\n",
    "        print(f'idx: {idx}, folder: {folder + \"/\" + idx + \"/Videos/\"}')\n",
    "        files = glob.glob(folder + '/' + idx + '/Videos/*')\n",
    "    else:\n",
    "        # print(f'idx: {idx}, folder: {folder + \"/\" + idx + \"/Video/\"}')\n",
    "        files = glob.glob(folder + '/' + idx + '/**/*.asf')    \n",
    "\n",
    "    # check for 827 or 984\n",
    "    if os.path.exists(folder + '/' + idx + '/827000/') or os.path.exists(folder + '/' + idx + '/984/'):\n",
    "        print(f'idx: {idx}, 827 or 984')\n",
    "        excluded_list.append(idx)\n",
    "        continue\n",
    "    \n",
    "    # check for 827000 or 984 in nested folder\n",
    "    if os.path.exists(folder + '/' + idx + '/Video/827000/') or os.path.exists(folder + '/' + idx + '/Video/984/'):\n",
    "        print(f'idx: {idx}, 827 or 984')\n",
    "        excluded_list.append(idx)\n",
    "        continue \n",
    "\n",
    "    if len(files) < 1:\n",
    "        print(f'idx: {idx}, files: {len(files)}')\n",
    "        excluded_list.append(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e633cf",
   "metadata": {},
   "source": [
    "### Validation for Empty Video Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d653d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: .DS_Store, files: 0\n",
      "idx: 1003_1004-nonAI, files: 0\n",
      "idx: 1005-nonAI, files: 0\n",
      "idx: 1043  1044, files: 0\n",
      "idx: 1082, files: 0\n",
      "idx: 1094, files: 0\n",
      "idx: 1119, files: 0\n",
      "idx: 1123, files: 0\n",
      "idx: 1129, files: 0\n",
      "idx: 2062, files: 0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "folder = 'Y:/VIDEOS'\n",
    "# video_list = glob.glob(folder + '/*/Video/**/*.asf')\n",
    "# video_list\n",
    "\n",
    "ids = os.listdir(folder)\n",
    "excluded_list = []\n",
    "for idx in ids:\n",
    "    files = glob.glob(folder + '/' + idx + '/Video/**/*.asf')\n",
    "    if len(files) < 1:\n",
    "        print(f'idx: {idx}, files: {len(files)}')\n",
    "        excluded_list.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_list = ['1009 1010',\n",
    "                 '1011 1012',\n",
    "                 '1003 1004',\n",
    "                 '1031 1017',\n",
    "                 '1011 1012',\n",
    "                 '1043 1044',\n",
    "                 '1055 1056',\n",
    "                 '1074 1075',\n",
    "                 '1099 1100',\n",
    "                 '1013 1014',\n",
    "                 '1003 1004-nonAI',\n",
    "                 '1005-nonAI',\n",
    "                 '1073',\n",
    "                 '1082',\n",
    "                 '1094',\n",
    "                 '1097',\n",
    "                 '2002',\n",
    "                 '2062'\n",
    "                 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672caf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import metaData\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47c2d0-3e97-4738-9004-7192341864f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'Datafiles/data_storage_Jan2023.json'\n",
    "with open(json_file) as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b329e-eec5-4096-9999-dca66580f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_list = {}\n",
    "days = []\n",
    "for i, d in enumerate(data['data'][:500]):\n",
    "    if d['id'] in days_list.keys():\n",
    "        days_list[d['id']].append(d['day'])\n",
    "    elif d['id'] not in days_list.keys():\n",
    "        days_list[d['id']] = list()\n",
    "        days_list[d['id']].append(d['day'])\n",
    "    # print(f\"Index: {i}, Data: {d['day']}\")\n",
    "    # days.append(d['day'])\n",
    "\n",
    "days_list_sorted = {k: sorted(v) for k, v in days_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c16497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(json_file)\n",
    "dt = pd.DataFrame(df['data'], columns=['id', 'day', 'duration'])\n",
    "\n",
    "\n",
    "jn = pd.json_normalize(df['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fa3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = []\n",
    "ts_list = []\n",
    "for col, row in jn.iloc[:10].iterrows():\n",
    "    for idx in row:\n",
    "        # col_list.append(idx)\n",
    "        if type(idx) == list and len(idx) > 0:\n",
    "            for item in idx:\n",
    "                ts_list.append(item)\n",
    "        else:\n",
    "            col_list.append(idx)\n",
    "            if ts_list != []:\n",
    "                col_list.append(ts_list)\n",
    "                ts_list = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2302bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jn.columns\n",
    "\n",
    "ts_cols = ['yawn.timestamp',\n",
    "           'smoking.timestamp',\n",
    "           'mobilephone.timestamp',\n",
    "           'distraction.timestamp',\n",
    "           'eyeclosing.timestamp',\n",
    "           'crossinglane.timestamp',\n",
    "           'nearcollision.timestamp',\n",
    "           'stopsign.timestamp',\n",
    "           'redlight.timestamp',\n",
    "           'pedestrian.timestamp',\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f0e37",
   "metadata": {},
   "source": [
    "### Data Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef44c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sort a list of dictionaries by value1 and value2\n",
    "def sort_list_of_dict_by_value(list_of_dict, value1, value2):\n",
    "    return sorted(list_of_dict, key=lambda k: (k[value1], k[value2]))\n",
    "\n",
    "\n",
    "# get next 90 days from a given date\n",
    "# return a single date for next 90 days\n",
    "def get_next_90_days(start_date):\n",
    "    yyyy = start_date[:4]\n",
    "    mm = start_date[4:6]\n",
    "    dd = start_date[6:]\n",
    "\n",
    "    converted_date = datetime.datetime(int(yyyy), int(mm), int(dd))\n",
    "    next_months = converted_date + datetime.timedelta(days=90)\n",
    "    return str(next_months)[:10].replace('-', '')\n",
    "\n",
    "def get_next_90_days_data_from_sorted_list_of_dict(list_of_dict, value1, value2):\n",
    "    next_90_days = []\n",
    "    for i, d in enumerate(list_of_dict):\n",
    "        if i == len(list_of_dict)-1:\n",
    "            break\n",
    "        next_90_days.append(get_next_90_days(d[value2]))\n",
    "    return next_90_days\n",
    "\n",
    "# calculate number of day between two dates\n",
    "def days_between(d1, d2):\n",
    "    d1 = datetime.datetime.strptime(d1, \"%Y%m%d\")\n",
    "    d2 = datetime.datetime.strptime(d2, \"%Y%m%d\")\n",
    "    return abs((d2 - d1).days)\n",
    "\n",
    "# days_between('20200301', '20200102')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86273cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = sort_list_of_dict_by_value(data['data'], 'id', 'day')\n",
    "d = get_next_90_days_data_from_sorted_list_of_dict(sl, 'id', 'day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e29d4e",
   "metadata": {},
   "source": [
    "### Extracting Data Based on Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4cb3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filePath = 'Z:/VIDEOS/1010/Disk_files/debug/'\n",
    "def extract_indices_from_log(filePath,file):\n",
    "    alarmsDict = {'NOBODY': 0, 'LOOKING_DOWN': 0, 'SMOKING': 0, 'CALLING':0, 'LDW': 0, 'EYE_CLOSED': 0, 'LDW_R': 0, 'LDW_L':0, 'FCW':0, 'camera cover!':0, 'infrared block!': 0 }\n",
    "    alarmsTimeStamp = {'NOBODY': [], 'LOOKING_DOWN': [], 'SMOKING': [], 'CALLING':[], 'LDW': [], 'EYE_CLOSED': [], 'LDW_R': [], 'LDW_L':[], 'FCW':[], 'camera cover!':[], 'infrared block!': [] }\n",
    "    # alarmsDict = {'alarm_type 5': 0, 'alarm_type 4': 0, 'alarm_type 3': 0, 'alarm_type 1': 0, 'alarm_type 2': 0, 'alarm_type 17': 0, 'alarm_type 18': 0, 'alarm_type 27':0, 'alarm_type 16':0, 'alarm_type 9':0, 'alarm_type 7': 0 }\n",
    "    # alarmsTimeStamp = {'alarm_type 5': [], 'alarm_type 4': [], 'alarm_type 3': [], 'alarm_type 1': [], 'alarm_type 2': [], 'alarm_type 17': [], 'alarm_type 18': [], 'alarm_type 27':[], 'alarm_type 16':[], 'alarm_type 9':[], 'alarm_type 7': [] }\n",
    "    \n",
    "    error_files = []\n",
    "    # print(f\"Processing debug file {file}\")\n",
    "    with open(os.path.join(filePath, file), 'r') as logFile:\n",
    "        lines = logFile.read().splitlines()\n",
    "        for line in lines:\n",
    "            words = line.split(\" \")\n",
    "            \"\"\"\n",
    "            Retrieve alarm will be here\n",
    "            \"\"\"\n",
    "            for alarm in alarmsDict.keys():\n",
    "                if alarm in words:\n",
    "                    alarmsDict[alarm] += 1\n",
    "                    # below is date extraction so needs to be corrected****** --> currently is this -->[20210504-140826][03][baseIVS]\n",
    "                    try:\n",
    "                        timestamp = \"\".join(words[0].split('[')[1].split('-')).strip(']')\n",
    "                        alarmsTimeStamp[alarm].append(timestamp)\n",
    "                    except Exception:\n",
    "                        error_files.append(file)\n",
    "\n",
    "        # logFile.close()\n",
    "        # print(alarmsDict)\n",
    "    return alarmsDict, alarmsTimeStamp, error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_list = ['1003 1004','1031 1017','1011 1012','1043 1044','1013 1014','1003 1004-nonAI', '1005-nonAI', '1073', '2062']\n",
    "ids = []\n",
    "for item in os.listdir('Z:/VIDEOS/'):\n",
    "    if item not in excluded_list:\n",
    "        ids.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile = []\n",
    "mapping = {'NOBODY': 0,\n",
    "           'LOOKING_DOWN': 1,\n",
    "           'SMOKING': 2, \n",
    "           'CALLING': 3, \n",
    "           'LDW': 5, \n",
    "           'EYE_CLOSED': 4, \n",
    "           'LDW_R': 5, \n",
    "           'LDW_L':5, \n",
    "           'FCW':6, \n",
    "           'camera cover!':0, \n",
    "           'infrared block!': 0 }\n",
    "    \n",
    "for each_driver in tqdm(ids):\n",
    "    logFolder = f'Z:/VIDEOS/{each_driver}/Disk_files/debug/'\n",
    "    for logfile in os.listdir(logFolder):\n",
    "        driverid = logFolder.split('/')[2]\n",
    "        \n",
    "        # if logfile.endswith('.log'):\n",
    "        alarmdict, alarmtimestamp, err = extract_indices_from_log(logFolder, logfile)\n",
    "        for key, value in alarmtimestamp.items():\n",
    "            for ts in value:\n",
    "                if key != 'NOBODY':\n",
    "                    id = driverid\n",
    "                    alarm_type = key\n",
    "                    date = ts[:9]\n",
    "                    \n",
    "                    transform_dict = {'id': id, 'date': date, 'timestamp': ts, 'type': mapping[alarm_type]}\n",
    "                    jsonfile.append(transform_dict)\n",
    "\n",
    "with open('./Datafiles/Timestamps_data.json', 'w') as jsonf:\n",
    "    json.dump(jsonfile, jsonf)    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Formatting the data to used in excel reprots\n",
    "import json\n",
    "\n",
    "with open('data_storage.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for each_item in data['data']:\n",
    "    each_item.update"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe2fb9a6",
   "metadata": {},
   "source": [
    "### Uploading Data to HPC Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c7b97bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Exists 827000\n",
      "Formatting the folder structure for Source: K:/Videos/1001/Video/827000\n",
      "Destination Folder: K:/Videos/1001/Video\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28136\\4129564532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m#  this restructure the folders to same as on server\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m# 984/827000 still exists - delete manually\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mvalidation_of_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# transfer the file to hpc server\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28136\\4129564532.py\u001b[0m in \u001b[0;36mvalidation_of_structure\u001b[1;34m(src)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/Video/827000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Folder Exists 827000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mpreparing_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34mf'/Video/827000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/Video/984'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Folder Exists 984'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28136\\4129564532.py\u001b[0m in \u001b[0;36mpreparing_folder\u001b[1;34m(src)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Destination Folder: {dest}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mcopy_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Completed the formatting of folder structure for {src}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\distutils\\dir_util.py\u001b[0m in \u001b[0;36mcopy_tree\u001b[1;34m(src, dst, preserve_mode, preserve_times, preserve_symlinks, update, verbose, dry_run)\u001b[0m\n\u001b[0;32m    157\u001b[0m                 copy_tree(src_name, dst_name, preserve_mode,\n\u001b[0;32m    158\u001b[0m                           \u001b[0mpreserve_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_symlinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                           verbose=verbose, dry_run=dry_run))\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             copy_file(src_name, dst_name, preserve_mode,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\distutils\\dir_util.py\u001b[0m in \u001b[0;36mcopy_tree\u001b[1;34m(src, dst, preserve_mode, preserve_times, preserve_symlinks, update, verbose, dry_run)\u001b[0m\n\u001b[0;32m    161\u001b[0m             copy_file(src_name, dst_name, preserve_mode,\n\u001b[0;32m    162\u001b[0m                       \u001b[0mpreserve_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m                       dry_run=dry_run)\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\distutils\\file_util.py\u001b[0m in \u001b[0;36mcopy_file\u001b[1;34m(src, dst, preserve_mode, preserve_times, update, link, verbose, dry_run)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;31m# Otherwise (non-Mac, not linking), copy the file contents and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;31m# (optionally) copy the times and mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0m_copy_file_contents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpreserve_mode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpreserve_times\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\distutils\\file_util.py\u001b[0m in \u001b[0;36m_copy_file_contents\u001b[1;34m(src, dst, buffer_size)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mfdst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mfsrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "\n",
    "\n",
    "# def transferFilesToServer(src, dest):\n",
    "#     # files = glob.glob(src, recursive=True)\n",
    "#     # for root, dirs, files in os.walk(src):\n",
    "#     #     root = \"/\".join(root.split('\\\\'))\n",
    "#     #     after_root = \"/\".join(root.split('/')[3:])\n",
    "#     #     for each_dir in dirs:\n",
    "#     #         if os.path.exists(dest+after_root+each_dir):\n",
    "#     #             continue\n",
    "#     #         else:\n",
    "#     #             os.umask(0)\n",
    "                \n",
    "#     #             os.mkdir(dest+after_root+'/'+each_dir, mode=0o777)\n",
    "        \n",
    "#     #     for file in files:\n",
    "#     #         shutil.copy(root+'/'+file, dest+after_root+'/')\n",
    "        \n",
    "#     return f'Total File : {print(len(os.listdir(dest)))}'\n",
    "\n",
    "def transferFilesToServer(src, dst):\n",
    "    print('Started copying the files...')\n",
    "    copy_tree(src, dst)\n",
    "    return 'All files copied successfully'\n",
    "\n",
    "# No '/' at end of src\n",
    "def validation_of_structure(src, participant_id):\n",
    "    \n",
    "    if os.path.exists(src+'/Video/827000'):\n",
    "        print(f'Folder Exists 827000')\n",
    "        preparing_folder(src+f'/Video/827000')\n",
    "        \n",
    "        os.mkdir(f'K:/Backup/{participant_id}')\n",
    "    elif os.path.exists(src+'/Video/984'):\n",
    "        print(f'Folder Exists 984')\n",
    "        preparing_folder(src+f'/Video/984')\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def preparing_folder(src):\n",
    "    print(f'Formatting the folder structure for Source: {src}')\n",
    "    \n",
    "    dest = \"/\".join(src.split('/')[:-1])\n",
    "    print(f'Destination Folder: {dest}')\n",
    "    \n",
    "    copy_tree(src, dest)\n",
    "    \n",
    "    # make backup and transfer files\n",
    "    copy_tree(src, 'K:/Backup/')\n",
    "    print(f'Completed the formatting of folder structure for {src}')\n",
    "\n",
    "# src = 'K:/Videos/1040/'\n",
    "# dest = 'K:/Z/1122/'\n",
    "\n",
    "source = 'K:/Videos/1001'\n",
    "destination = 'Z:/1001'\n",
    "participant_id = '1001'\n",
    " \n",
    "#  this restructure the folders to same as on server\n",
    "# 984/827000 still exists - delete manually\n",
    "validation_of_structure(source, participant_id)\n",
    "\n",
    "# transfer the file to hpc server\n",
    "transferFilesToServer(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a581b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.exists('K:/Z/1022/Video/2021-11-06/T084931000000.asf')\n",
    "# copy_tree(source, destination,)\n",
    "\n",
    "shutil.rmtree('k:/Z/1122/Video/2021-11-02')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a56290a",
   "metadata": {},
   "source": [
    "### Splitting of Driver files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b26ca1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'male': 2668, 'female': 25, 'None': 23}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "def gender_stats_from_txtFile(file):\n",
    "    gender_list = {'male': 0, 'female':0, 'None':0}\n",
    "    with open(file) as f:\n",
    "        list_of_files = json.load(f)\n",
    "    for file in list_of_files:\n",
    "        for file, gender in file.items():\n",
    "            gender_list[gender] += 1\n",
    "    # print(f\"Total Stats: {gender_list}\")\n",
    "    return gender_list\n",
    "\n",
    "# g_rest = gender_stats_from_txtFile('gender_deepface_1013_1014.json')\n",
    "# g_1000 = gender_stats_from_txtFile('gender_deepface_1013_1014.txt')\n",
    "\n",
    "gender_stats_from_txtFile('gender_1013_1014.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c62bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two json files and save it to a new file\n",
    "def combine_two_list(list1, list2):\n",
    "    return list1 + list2\n",
    "\n",
    "with open('gender_deepface_1013_1014.json') as f1:\n",
    "    l1 = json.load(f1)\n",
    "\n",
    "\n",
    "with open('gender_deepface_1013_1014.txt') as f2:\n",
    "    l2 = json.load(f2)\n",
    "\n",
    "combined_list = combine_two_list(l1, l2)\n",
    "\n",
    "with open('gender_1013_1014.txt', 'w') as f:\n",
    "    json.dump(combined_list, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tinytag import TinyTag\n",
    "path = 'Z:/VIDEOS/1013_male/Video/'\n",
    "length = len(glob.glob(path+'**/*000.asf'))\n",
    "\n",
    "\n",
    "def get_meta(path):\n",
    "    \n",
    "    # path = os.path.join(path, file)\n",
    "    video = TinyTag.get(path)\n",
    "    video_dict = {\"album\" : video.album,\n",
    "                  \"albumartist\": video.albumartist,\n",
    "                  \"artist\" : video.artist,\n",
    "                  \"aurdio_offset\": video.audio_offset,\n",
    "                  \"bitrate\" : video.bitrate,\n",
    "                  \"comment\" : video.comment,\n",
    "                  \"composer\" : video.composer,\n",
    "                  \"disc\" : video.disc,\n",
    "                  \"disc_total\" : video.disc_total,\n",
    "                  \"duration\" : video.duration,\n",
    "                  \"filesize\" : video.filesize,\n",
    "                  \"genre\" :video.genre,\n",
    "                  \"samplerate\" : video.samplerate,\n",
    "                  \"title\" : video.title,\n",
    "                  \"track\" : video.track,\n",
    "                  \"track_total\" : video.track_total,\n",
    "                  \"year\" : video.year}\n",
    "\n",
    "    # with open('indices.json', 'w') as json_file:\n",
    "    #     json.dump(dict(video_dict), json_file)\n",
    "    return video_dict\n",
    "\n",
    "def get_duration_modified(path):\n",
    "    f_dict = {}\n",
    "    # Glob - getting list of files\n",
    "    counter = 0\n",
    "    total_fileList = len(glob.glob(path+'**/*000.asf'))\n",
    "    \n",
    "    for file in glob.glob(path+'**/*000.asf'):\n",
    "        dur = 0\n",
    "        file = file.replace('\\\\', '/')\n",
    "        metas = get_meta(file)\n",
    "        try:\n",
    "            if metas['duration'] < 10000:\n",
    "                # print(f'Duration: {metas[\"duration\"]}')\n",
    "                dur += int(metas['duration'])\n",
    "        except:\n",
    "            dur += 0\n",
    "            print(f'get_duration()::Error During Processing: {file}')\n",
    "        dir_split = \"\".join(file.split(\"/\")[-1].split(\"-\"))\n",
    "        print(f'Processing : {counter}/{total_fileList}, File: {dir_split}')\n",
    "        counter += 1\n",
    "        print(f_dict)\n",
    "        f_dict[dir_split] = dur\n",
    "    \n",
    "    return f_dict\n",
    "\n",
    "get_duration_modified(path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Driver_indices-DsFqzCcB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5dd92fb0320f6de981139fad36e905da6c43d5f0ca47ced40c32e9f3f500edc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
